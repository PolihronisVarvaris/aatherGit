# Aather - Personal Assistant for Visually Impaired Users
![aatherthesis](https://github.com/user-attachments/assets/a917e3d4-04d3-469f-a1d2-0831a0c407df)

## Thesis and rest of the files
**https://drive.google.com/drive/folders/1DssyG4b9f5sKoNC9UCJBVSZlvb0EUiYm?usp=sharing**

## Overview
Aather is an Android mobile application designed to assist individuals with visual and auditory impairments in their daily lives. The application integrates modern technologies such as voice recognition, image processing, and real-time data handling to offer an accessible and user-friendly experience.

## Features
- **Image Recognition**: Assists in identifying objects, text, and colors for visually impaired users.
- **Sign Language Learning**: Provides an AI-powered tool to recognize and teach sign language (GSL).
- **Live Assistance**: Connects users with volunteers for real-time support (Currently in development).
- **Accessibility Tools**: Includes magnifiers, text-to-speech conversion etc.
- **Emergency SOS**: A dedicated emergency feature for quick assistance.

![applibannerleit](https://github.com/user-attachments/assets/40e9f6ab-e73d-4cb3-99e0-59b06d836e62)

## Technologies Used
- **Programming Language**: Kotlin
- **Frameworks & Tools**: Android Studio, Firebase, TensorFlow Lite
- **APIs & Libraries**: OpenCV, Google Text-to-Speech, Live Transcribe API

## Installation
1. Clone the repository:
   ```sh
   git clone https://github.com/your-repo/Aather.git
   ```
2. Open the project in Android Studio.
3. Sync Gradle dependencies.
4. Run the application on an emulator or physical device.

## Contribution Guidelines
- Fork the repository and create a new branch for your feature.
- Submit a pull request with detailed descriptions of your changes.
- Ensure all code follows the accessibility and usability standards.

## Acknowledgments
Special thanks to the faculty of the **International Hellenic University**, Department of Information and Electronic Systems Engineering, for their support in the development of this project.

